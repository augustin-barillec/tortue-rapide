{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from augmentation import *\n",
    "from model import default_categorical\n",
    "from utils import linear_bin, tub_to_array, rebalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVAILABLE TUBS\n",
    "tub_20181113_42_afternoon = '/home/data/tortue-rapide/tubs/raw/tub_20181113_42_afternoon'\n",
    "tub_20181113_42_evening = '/home/data/tortue-rapide/tubs/raw/tub_20181113_42_evening'\n",
    "tub_20181124_morning_lesquare_horaire = '/home/data/tortue-rapide/tubs/raw/tub_20181124_morning_lesquare_horaire'\n",
    "tub_20181124_morning_lesquare_antihoraire = '/home/data/tortue-rapide/tubs/raw/tub_20181124_morning_lesquare_antihoraire'\n",
    "tub_20181122_ysance_noon = '/home/data/tortue-rapide/tubs/raw/tub_20181122_ysance_noon'\n",
    "\n",
    "# EXAMPLES\n",
    "img_example = '/home/projects/ironcar-dev/tubs/tub_20181124_morning_lesquare_antihoraire/291_cam-image_array_.jpg'\n",
    "json_exple = '/home/projects/ironcar-dev/tubs/tub_20181124_morning_lesquare_antihoraire/record_291.json'\n",
    "\n",
    "save_model_path = '/home/projects/tortue-rapide/franklin_gym/test_models'\n",
    "\n",
    "# convert tubs to numpy arrays\n",
    "x_42_afternoon, y_42_afternoon = tub_to_array(tub_20181113_42_afternoon, n_class=3)\n",
    "x_42_evening, y_42_evening = tub_to_array(tub_20181113_42_evening, n_class=3)\n",
    "x_morning_lesquare_horaire, y_morning_lesquare_horaire = tub_to_array(tub_20181124_morning_lesquare_horaire, n_class=3)\n",
    "x_morning_lesquare_antihoraire, y_morning_lesquare_antihoraire = tub_to_array(tub_20181124_morning_lesquare_antihoraire, n_class=3)\n",
    "X_ysance_noon, Y_ysance_noon = tub_to_array(tub_20181122_ysance_noon, n_class=3)\n",
    "\n",
    "# rebalance ecole 42 tubs  classes\n",
    "x_42_afternoon, y_42_afternoon = rebalance(x_42_afternoon, y_42_afternoon)\n",
    "x_42_evening, y_42_evening = rebalance(x_42_evening, y_42_evening)\n",
    "x_morning_lesquare_horaire, y_morning_lesquare_horaire = rebalance(x_morning_lesquare_horaire, y_morning_lesquare_horaire)\n",
    "\n",
    "# train / validation split\n",
    "X_train = np.concatenate((x_42_afternoon, x_morning_lesquare_antihoraire, x_morning_lesquare_horaire))\n",
    "Y_train = np.concatenate((y_42_afternoon, y_morning_lesquare_antihoraire, y_morning_lesquare_horaire)) \n",
    "X_val, Y_val = X_ysance_noon[:20000], Y_ysance_noon[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5114)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hist(Y):\n",
    "    '''\n",
    "    Y : categorical numpy array'''\n",
    "    fi = [sum(n * a) for n in Y]\n",
    "    plt.hist(fi, bins='auto')\n",
    "\n",
    "plot_hist(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAP DATA PREPARATION\n",
    "\n",
    "train_tubs = ['tub_20181113_42_afternoon', \n",
    "              'tub_20181113_42_evening',\n",
    "              'tub_20181124_morning_lesquare_antihoraire']\n",
    "validation_tubs = ['tub_20181122_ysance_noon']\n",
    "\n",
    "rebalance_tubs = ['tub_20181113_42_afternoon', \n",
    "                  'tub_20181113_42_evening']\n",
    "\n",
    "# 'tweak_luminosity'\n",
    "# 'add_snow'\n",
    "# 'add_shadow'\n",
    "# 'add_blur'\n",
    "# 'add_gaussian_noise'\n",
    "# 'random_shadows'\n",
    "# 'generate_night_effect' \n",
    "# 'generate_brightness'\n",
    "# 'generate_contrast_normalization'\n",
    "augmentation_functions = ['tweak_luminosity', 'generate_contrast_normalization']\n",
    "\n",
    "PROPORTION = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 251/1210 [00:00<00:00, 2505.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12100 samples\n",
      "tweak_luminosity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1210/1210 [00:00<00:00, 2917.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13310 samples\n"
     ]
    }
   ],
   "source": [
    "print('{} samples'.format(len(X_train)))\n",
    "\n",
    "for augment in augmentation_functions:\n",
    "    if augment in transform_dict.keys():\n",
    "        print(augment)\n",
    "        f = transform_dict[augment]\n",
    "        X_transfo, Y_transfo = transform(X_train, Y_train, transformation=f, proportion=PROPORTION)\n",
    "        X_train = np.concatenate((X_train, X_transfo))\n",
    "        Y_train = np.concatenate((Y_train, Y_transfo)) \n",
    "        \n",
    "\n",
    "print('{} samples'.format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7965"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ori = np.concatenate((image_ori, image_HLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 120, 160, 3)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bight_x_train_5eme, bright_y_train_5eme = aug.generate_brightness(X_train, Y_train)\n",
    "bight_x_train_5eme, bright_y_train_5eme = aug.generate_night_effect(X_train, Y_train)\n",
    "bight_x_train_5eme, bright_y_train_5eme = aug.generate_random_shadows(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)    (None, 80, 160, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 38, 78, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 17, 37, 32)        19232     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 17, 64)         51264     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "angle_cat_out (Dense)        (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 189,879\n",
      "Trainable params: 189,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7965 samples, validate on 5114 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "epochs=100\n",
    "steps=100\n",
    "verbose=1\n",
    "min_delta=.0005\n",
    "patience=5\n",
    "use_early_stop=True\n",
    "\n",
    "\n",
    "model = default_categorical()\n",
    "\n",
    "# checkpoint to save model after each epoch\n",
    "save_best = ModelCheckpoint(save_model_path,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=verbose,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n",
    "\n",
    "# stop training if the validation error stops improving.\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=min_delta,\n",
    "                           patience=patience,\n",
    "                           verbose=verbose,\n",
    "                           mode='auto')\n",
    "\n",
    "callbacks_list = [save_best]\n",
    "\n",
    "if use_early_stop:\n",
    "    callbacks_list.append(early_stop)\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "# fit from numpy array\n",
    "hist = model.fit(x=X_train,\n",
    "                 y=Y_train,\n",
    "                 steps_per_epoch=steps,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, Y_val),\n",
    "                 callbacks=callbacks_list,\n",
    "                 validation_steps=200/8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure:\n",
    "- import data\n",
    "- train (3 tubs) / test (1 different tub) split\n",
    "- apply data augmentations\n",
    "- train + validate\n",
    "\n",
    "Interface\n",
    "testor.benchmark([['processing1', 'processing2'], \n",
    "                  ['processing4', 'processing2', 'processing5']])\n",
    "                  \n",
    "generate_brightness\n",
    "generate_night_effect\n",
    "generate_random_shadows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://rec-nexus.dmp.y-track.com/repository/pypi-all/simple\n",
      "Collecting pip\n",
      "  Using cached https://rec-nexus.dmp.y-track.com/repository/pypi-all/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-19.0.3\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tweak_luminosity(image):\n",
    "    image_HLS = cv2.cvtColor(image, cv2.COLOR_BGR2HLS) ## Conversion to HLS\n",
    "    random_brightness_coefficient = np.random.uniform()+0.5 ## generates value between 0.5 and 1.5\n",
    "    image_HLS[:,:,1] = image_HLS[:,:,1]*random_brightness_coefficient ## scale pixel values up or down for channel 1(Lightness)\n",
    "    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255 ##Sets all values above 255 to 255\n",
    "    image_HLS = np.array(image_HLS, dtype = np.uint8)\n",
    "    image_RGB = cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n",
    "    return image_RGB\n",
    "\n",
    "def add_snow(image):\n",
    "    image_HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS) ## Conversion to HLS\n",
    "    image_HLS = np.array(image_HLS, dtype = np.float64) \n",
    "    brightness_coefficient = 2.5 \n",
    "    snow_point=60 ## increase this for more snow\n",
    "    image_HLS[:,:,1][image_HLS[:,:,1]<snow_point] = image_HLS[:,:,1][image_HLS[:,:,1]<snow_point]*brightness_coefficient ## scale pixel values up for channel 1(Lightness)\n",
    "    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255 ##Sets all values above 255 to 255\n",
    "    image_HLS = np.array(image_HLS, dtype = np.uint8)\n",
    "    image_RGB = cv2.cvtColor(image_HLS, cv2.COLOR_HLS2RGB) ## Conversion to RGB\n",
    "    return image_RGB\n",
    "\n",
    "def shadow_coordinates(imshape, no_of_shadows=2):\n",
    "    vertices_list=[]\n",
    "    for index in range(no_of_shadows):\n",
    "        vertex=[]\n",
    "        for dimensions in range(np.random.randint(3,15)): ## Dimensionality of the shadow polygon\n",
    "            vertex.append(( imshape[1]*np.random.uniform(),imshape[0]//3+imshape[0]*np.random.uniform()))\n",
    "        vertices = np.array([vertex], dtype=np.int32) ## single shadow vertices \n",
    "        vertices_list.append(vertices)\n",
    "    return vertices_list ## List of shadow vertices\n",
    "\n",
    "\n",
    "def add_shadows(image, no_of_shadows=2):\n",
    "    image_HLS = cv2.cvtColor(image,cv2.COLOR_RGB2HLS) ## Conversion to HLS\n",
    "    mask = np.zeros_like(image) \n",
    "    imshape = image.shape\n",
    "    vertices_list = shadow_coordinates(imshape, no_of_shadows) #3 getting list of shadow vertices\n",
    "    for vertices in vertices_list: \n",
    "        cv2.fillPoly(mask, vertices, 255) ## adding all shadow polygons on empty mask, single 255 denotes only red channel\n",
    "    \n",
    "    image_HLS[:,:,1][mask[:,:,0]==255] = image_HLS[:,:,1][mask[:,:,0]==255]*0.5   ## if red channel is hot, image's \"Lightness\" channel's brightness is lowered \n",
    "    image_RGB = cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB) ## Conversion to RGB\n",
    "    return image_RGB\n",
    "\n",
    "def add_blur(images):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "    ])\n",
    "    \n",
    "    aug_images = seq.augment_images(image_ori)\n",
    "    \n",
    "    return aug_images\n",
    "\n",
    "def add_gaussian_noise(images):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.08*255))\n",
    "    ])\n",
    "    \n",
    "    aug_images = seq.augment_images(image_ori)\n",
    "    \n",
    "    return aug_images\n",
    "\n",
    "\n",
    "def add_contrast_normalization(images):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.ContrastNormalization((0.2, 1.5))\n",
    "    ])\n",
    "    \n",
    "    aug_images = seq.augment_images(image_ori)\n",
    "    \n",
    "    return aug_images\n",
    "\n",
    "\n",
    "def transform(X, Y, transformation, proportion=0.25):\n",
    "    # Generate a random selection of indexes\n",
    "    indexes = random.sample(range(0, X.shape[0]), int(X.shape[0]*proportion))\n",
    "    \n",
    "    X_aug = []\n",
    "    Y_aug = []\n",
    "    for index in tqdm(indexes):\n",
    "        im = transformation(X[index])\n",
    "        X_aug.append(im)\n",
    "        Y_aug.append(Y[index])\n",
    "\n",
    "    return np.asarray(X_aug), np.asarray(Y_aug)\n",
    "\n",
    "# augmentation dict\n",
    "transform_dict = {\n",
    "    'tweak_luminosity': tweak_luminosity,\n",
    "    'add_snow': add_snow,\n",
    "    'add_shadow': add_shadow,\n",
    "    'add_blur': add_blur,\n",
    "    'add_gaussian_noise': add_gaussian_noise,\n",
    "    'add_shadows': add_shadows,\n",
    "    'add_contrast_normalization': add_contrast_normalization\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
